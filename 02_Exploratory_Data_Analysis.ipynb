{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Exploratory Data Analysis (EDA) on the Kings County Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.9 or later is installed (ideally I would generatlly recommend Python 3.10), as well as Scikit-Learn ≥ 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from statsmodels) (2.3.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from statsmodels) (2.3.2)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harsimarbrar/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.6-cp312-cp312-macosx_11_0_arm64.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.2 statsmodels-0.14.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.9 is required\n",
    "%pip install scikit-learn\n",
    "%pip install statsmodels\n",
    "import sys\n",
    "assert sys.version_info >= (3, 9)\n",
    "\n",
    "# Scikit-Learn ≥1.0 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"1.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Precision options\n",
    "np.set_printoptions(precision=2)\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Statistical analysis and testing\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the Data\n",
    "\n",
    "First of all let's import the data from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\n",
    "    \"/Users/harsimarbrar/Oxford/Courses/ml_ai_git_repo/mlai/kings_county_house_data.csv\",\n",
    "    dtype={'zipcode': str}   # US ZIP codes look like numbers but we want to treat them like strings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an overall idea of the fields available using the `DataFrame.info()` and `DataFrame.describe()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  object \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(14), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>8565900160</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>995000.000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2340</td>\n",
       "      <td>13406</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2340</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.538</td>\n",
       "      <td>-122.221</td>\n",
       "      <td>2340</td>\n",
       "      <td>10743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>1774220400</td>\n",
       "      <td>20140513T000000</td>\n",
       "      <td>591000.000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2710</td>\n",
       "      <td>38180</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98077</td>\n",
       "      <td>47.770</td>\n",
       "      <td>-122.097</td>\n",
       "      <td>2590</td>\n",
       "      <td>38180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>8039900400</td>\n",
       "      <td>20140812T000000</td>\n",
       "      <td>375000.000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1670</td>\n",
       "      <td>13775</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98045</td>\n",
       "      <td>47.487</td>\n",
       "      <td>-121.783</td>\n",
       "      <td>2130</td>\n",
       "      <td>14500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>8906200070</td>\n",
       "      <td>20150210T000000</td>\n",
       "      <td>280000.000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1670</td>\n",
       "      <td>11610</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98055</td>\n",
       "      <td>47.440</td>\n",
       "      <td>-122.191</td>\n",
       "      <td>1930</td>\n",
       "      <td>10200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>2426039247</td>\n",
       "      <td>20150325T000000</td>\n",
       "      <td>299950.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1390</td>\n",
       "      <td>1756</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1390</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.727</td>\n",
       "      <td>-122.357</td>\n",
       "      <td>1340</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date      price  bedrooms  bathrooms  \\\n",
       "2395   8565900160  20150326T000000 995000.000         4      2.250   \n",
       "11189  1774220400  20140513T000000 591000.000         4      2.250   \n",
       "10978  8039900400  20140812T000000 375000.000         3      2.000   \n",
       "504    8906200070  20150210T000000 280000.000         3      1.500   \n",
       "11691  2426039247  20150325T000000 299950.000         2      1.500   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "2395          2340     13406   1.000           0     0  ...      9   \n",
       "11189         2710     38180   2.000           0     0  ...      8   \n",
       "10978         1670     13775   1.000           0     0  ...      8   \n",
       "504           1670     11610   1.000           0     0  ...      7   \n",
       "11691         1390      1756   3.000           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode    lat  \\\n",
       "2395         2340              0      1963             0    98040 47.538   \n",
       "11189        2710              0      1977             0    98077 47.770   \n",
       "10978        1670              0      1968             0    98045 47.487   \n",
       "504          1670              0      1963             0    98055 47.440   \n",
       "11691        1390              0      2005             0    98133 47.727   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "2395  -122.221           2340       10743  \n",
       "11189 -122.097           2590       38180  \n",
       "10978 -121.783           2130       14500  \n",
       "504   -122.191           1930       10200  \n",
       "11691 -122.357           1340        1756  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "      <td>21613.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4580301520.865</td>\n",
       "      <td>540088.142</td>\n",
       "      <td>3.371</td>\n",
       "      <td>2.115</td>\n",
       "      <td>2079.900</td>\n",
       "      <td>15106.968</td>\n",
       "      <td>1.494</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.234</td>\n",
       "      <td>3.409</td>\n",
       "      <td>7.657</td>\n",
       "      <td>1788.391</td>\n",
       "      <td>291.509</td>\n",
       "      <td>1971.005</td>\n",
       "      <td>84.402</td>\n",
       "      <td>47.560</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>1986.552</td>\n",
       "      <td>12768.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2876565571.312</td>\n",
       "      <td>367127.196</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.770</td>\n",
       "      <td>918.441</td>\n",
       "      <td>41420.512</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.175</td>\n",
       "      <td>828.091</td>\n",
       "      <td>442.575</td>\n",
       "      <td>29.373</td>\n",
       "      <td>401.679</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.141</td>\n",
       "      <td>685.391</td>\n",
       "      <td>27304.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000102.000</td>\n",
       "      <td>75000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>290.000</td>\n",
       "      <td>520.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>290.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1900.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.156</td>\n",
       "      <td>-122.519</td>\n",
       "      <td>399.000</td>\n",
       "      <td>651.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2123049194.000</td>\n",
       "      <td>321950.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1427.000</td>\n",
       "      <td>5040.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1190.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1951.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.471</td>\n",
       "      <td>-122.328</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>5100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3904930410.000</td>\n",
       "      <td>450000.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1910.000</td>\n",
       "      <td>7618.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1560.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1975.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.572</td>\n",
       "      <td>-122.230</td>\n",
       "      <td>1840.000</td>\n",
       "      <td>7620.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7308900445.000</td>\n",
       "      <td>645000.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2550.000</td>\n",
       "      <td>10688.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2210.000</td>\n",
       "      <td>560.000</td>\n",
       "      <td>1997.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.678</td>\n",
       "      <td>-122.125</td>\n",
       "      <td>2360.000</td>\n",
       "      <td>10083.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9900000190.000</td>\n",
       "      <td>7700000.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>13540.000</td>\n",
       "      <td>1651359.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>9410.000</td>\n",
       "      <td>4820.000</td>\n",
       "      <td>2015.000</td>\n",
       "      <td>2015.000</td>\n",
       "      <td>47.778</td>\n",
       "      <td>-121.315</td>\n",
       "      <td>6210.000</td>\n",
       "      <td>871200.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       price  bedrooms  bathrooms  sqft_living  \\\n",
       "count      21613.000   21613.000 21613.000  21613.000    21613.000   \n",
       "mean  4580301520.865  540088.142     3.371      2.115     2079.900   \n",
       "std   2876565571.312  367127.196     0.930      0.770      918.441   \n",
       "min      1000102.000   75000.000     0.000      0.000      290.000   \n",
       "25%   2123049194.000  321950.000     3.000      1.750     1427.000   \n",
       "50%   3904930410.000  450000.000     3.000      2.250     1910.000   \n",
       "75%   7308900445.000  645000.000     4.000      2.500     2550.000   \n",
       "max   9900000190.000 7700000.000    33.000      8.000    13540.000   \n",
       "\n",
       "         sqft_lot    floors  waterfront      view  condition     grade  \\\n",
       "count   21613.000 21613.000   21613.000 21613.000  21613.000 21613.000   \n",
       "mean    15106.968     1.494       0.008     0.234      3.409     7.657   \n",
       "std     41420.512     0.540       0.087     0.766      0.651     1.175   \n",
       "min       520.000     1.000       0.000     0.000      1.000     1.000   \n",
       "25%      5040.000     1.000       0.000     0.000      3.000     7.000   \n",
       "50%      7618.000     1.500       0.000     0.000      3.000     7.000   \n",
       "75%     10688.000     2.000       0.000     0.000      4.000     8.000   \n",
       "max   1651359.000     3.500       1.000     4.000      5.000    13.000   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated       lat      long  \\\n",
       "count   21613.000      21613.000 21613.000     21613.000 21613.000 21613.000   \n",
       "mean     1788.391        291.509  1971.005        84.402    47.560  -122.214   \n",
       "std       828.091        442.575    29.373       401.679     0.139     0.141   \n",
       "min       290.000          0.000  1900.000         0.000    47.156  -122.519   \n",
       "25%      1190.000          0.000  1951.000         0.000    47.471  -122.328   \n",
       "50%      1560.000          0.000  1975.000         0.000    47.572  -122.230   \n",
       "75%      2210.000        560.000  1997.000         0.000    47.678  -122.125   \n",
       "max      9410.000       4820.000  2015.000      2015.000    47.778  -121.315   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "count      21613.000   21613.000  \n",
       "mean        1986.552   12768.456  \n",
       "std          685.391   27304.180  \n",
       "min          399.000     651.000  \n",
       "25%         1490.000    5100.000  \n",
       "50%         1840.000    7620.000  \n",
       "75%         2360.000   10083.000  \n",
       "max         6210.000  871200.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Description of the features:\n",
    "\n",
    "Here follows a detailed description of all the features (i.e. columns/variables) in the dataset.\n",
    "\n",
    "* **id** - unique identifier for a house\n",
    "* **date** - house was sold\n",
    "* **price** - price, our prediction target\n",
    "* **bedrooms** - number of Bedrooms/House\n",
    "* **bathrooms** - number of bedrooms\n",
    "* **sqft_living** - square footage of the home\n",
    "* **sqft_lot** - square footage of the entire lot\n",
    "* **floors** - total number of floors (levels) in house\n",
    "* **waterfront** - house which has a view to a waterfront\n",
    "* **view** - quality of view\n",
    "* **condition** - how good the condition is ( overall )\n",
    "* **grade** - overall grade given to the housing unit, based on King County grading system\n",
    "* **sqft_above** - square footage of house apart from basement\n",
    "* **sqft_basement** - square footage of the basement\n",
    "* **yr_built** - Built Year\n",
    "* **yr_renovated** - Year when house was renovated\n",
    "* **zipcode** - zip\n",
    "* **lat** - Latitude coordinate\n",
    "* **long** - Longitude coordinate\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbours\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbours"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "**Question:** which of these variables are quantitaive/numerical, ordinal, and categorical?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business problem\n",
    "\n",
    "We want to accurately predict the housing prices in the Kings county (Washington, US) based on the iformation available in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Training and Test Set\n",
    "\n",
    "Splitting the original dataset into training and test set should be done even before you start a more thorough Exploratory Data Analysis (EDA).\n",
    "\n",
    "Creating a test set is theoretically simple: pick some instances randomly, typically 20% of the dataset (or less if your dataset is very large), and set them aside. We will use a function from `scikit-learn` which splits a dataset into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Stratified split\n",
    "\n",
    "Using `train_test_split()` we would just be doing a simple randomized sampling. But this might not be a representative sampling of the whole dataset, if we do not preserve the proportions (or percentages) of significant input features. Let's hypothesize that we learned from expert the `sqft_living` field is an important predictor for the house price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.sqft_living.hist(bins=100, figsize=(14,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to preserve the same proportion of samples with respect to `sqft_living` is to use a stratified split. We can split the dataset in such a way that the proportion of samples wrt `sqft_living` is preserved across the training and test set. To do this we first need to convert `sqft_living` into a categorical/ordinal variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"sqft_living_cat\"] = pd.cut(\n",
    "    housing.sqft_living, \n",
    "    bins=[0., 1000., 2000., 3000., 4000., np.inf],\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    ")\n",
    "housing['sqft_living_cat'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['sqft_living_cat'].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers the class `StratifiedShuffleSplit` to perform stratified splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in splitter.split(housing, housing.sqft_living_cat):\n",
    "    train_set = housing.loc[train_index]\n",
    "    test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the proportion of samples wrt `sqft_living_cat` is preserved in training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.sqft_living_cat.value_counts() / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.sqft_living_cat.value_counts() / len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove the `sqft_living_cat` feature as we will not need it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (train_set, test_set):\n",
    "    set_.drop(\"sqft_living_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discover and Visualize the Data to Gain Insights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = train_set[\n",
    "    ['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', \n",
    "     'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "].plot.box(subplots=True, layout=(3, 3), figsize=(18,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_set[['price']].boxplot(figsize=(15,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot use the IQR method to display data and outliers(shape of the data) but in order to be get a list of identified outlier, we will need to use the mathematical formula and retrieve the outlier data.\n",
    "\n",
    "Wikipedia Definition:\n",
    "_The interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, $IQR = Q_3 − Q_1$.\n",
    "\n",
    "In other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data.\n",
    "\n",
    "It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers._\n",
    "\n",
    "If a data point is below $Q_1 - 1.5\\times IQR$ or above $Q_3 + 1.5\\times IQR$ then it's an outlier.\n",
    "\n",
    "![box-plot-summary](../images/box-plot-iqr.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1 \n",
    "<b>Exercise 1:</b> Compute for me the count of outliers in our training set with respect to the `price` feature. (Hint: check the `DataFrame.quantile()` method and find a way to count the occurrences of values in a column of a DataFrame.) Additionally, write the code to remove those outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write you solution here. Add as many cells as you see fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the outliers legitimate or should we remove them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize geographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(\n",
    "    kind=\"scatter\", x=\"long\", y=\"lat\", figsize=(15,10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind=\"scatter\", x=\"long\", y=\"lat\", alpha=0.1, figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some info to the plot:\n",
    "    * scale the size of the markers based on the surface areas of the house\n",
    "    * colour-code the dots based on the house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"long\",\n",
    "    y=\"lat\",\n",
    "    alpha=0.1,\n",
    "    figsize=(20,13),\n",
    "    s=train_set[\"sqft_living\"]/100,\n",
    "    label=\"sqft_living\",\n",
    "    c=\"price\",\n",
    "    cmap=plt.get_cmap('jet'),\n",
    "    colorbar=True\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same colormap (i.e. jet), we can try to improve the visualization above, setting an upper value that is reasonable, (i.e less or equal to QR3 + 1.5 IQR such as 1,000,000 $), and not the highest value in the range.\n",
    "\n",
    "We can create a custom discrete colorbar by using `matplotlib.colors.BoundaryNorm` as normalizer for your scatterplot. See the norm argument in `matplotlib.pyplot.scatter()`: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.jet  # define the colormap\n",
    "bounds = np.linspace(0, q3.price + 1.5 * iqr.price, 11) # define 11 evenly space\n",
    "\n",
    "# The matplotlib.colors.BoundaryNorm class is used to create a colormap based on discrete numeric intervals.\n",
    "norm = mpl.colors.BoundaryNorm(\n",
    "    bounds, # Monotonically increasing sequence of boundaries\n",
    "    cmap.N # Number of colors in the colormap to be used\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.scatter(\n",
    "    x=train_set[\"long\"],\n",
    "    y=train_set[\"lat\"],\n",
    "    alpha=0.1,\n",
    "    s=train_set[\"sqft_living\"]/100, # size of the dot\n",
    "    label=train_set[\"sqft_living\"],\n",
    "    c=train_set[\"price\"], # colour of the dot\n",
    "    cmap=cmap, # colour map \n",
    "    norm=norm # used to scale the color data, c, in the range 0 to 1, in order to map into the colormap cmap\n",
    ")\n",
    "plt.colorbar(label=\"Price\", orientation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to achieve the same result as above is to use a `matplotlib.colors.LinearSegmentedColormap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.jet  # define the colormap\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# force the first color entry to be grey\n",
    "cmaplist[0] = (.5, .5, .5, 1.0)\n",
    "\n",
    "# create the new map\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N\n",
    ")\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, q3.price + 1.5 * iqr.price, 11)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.scatter(\n",
    "    x=train_set[\"long\"], y=train_set[\"lat\"],\n",
    "    alpha=0.1,\n",
    "    s=train_set[\"sqft_living\"]/100, label=train_set[\"sqft_living\"],\n",
    "    c=train_set[\"price\"], cmap=cmap, norm=norm\n",
    ")\n",
    "plt.colorbar(label=\"Price\", orientation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "**Question:** What insights can we infer from this graph?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "<b>Exercise 2:</b> explore on your own other ways to improve the graph above. You could look for ways to overlap it on top of the county map, or you could see if you can encode information differently.\n",
    "\n",
    "Map support can be provided using either [Basemap](https://basemaptutorial.readthedocs.io/en/latest/) or [folium](https://python-visualization.github.io/folium/).\n",
    "* To install basemap: `conda install -c conda-forge basemap basemap-data-hires`\n",
    "* To install folium: `conda install -c conda-forge folium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your possible solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numerical features: looking for correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not that big, and we can compute the standard correlation coefficient (Pearson’s r coefficient) between every two features using the `DataFrame.corr()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_set.corr(numeric_only=True)\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. The correlation coefficient only measures linear correlations, and it may completely miss nonlinear correlation factors. \n",
    "\n",
    "Another way to check for correlation visually is to use the `scatter_matrix()` utility function offered by Pandas, which leverages `matplotlib`, or seaborn's `pairplot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    \"price\", \"sqft_living\", \"grade\",\n",
    "    \"sqft_above\", \"sqft_living15\", \"bathrooms\"\n",
    "]\n",
    "pd.plotting.scatter_matrix(\n",
    "    train_set[attributes], figsize=(15, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pairplot(train_set[attributes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numerical features: checking for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate copy of df without target variable (price), id, date and lat/lon to perform multicolinearity check\n",
    "train_set_pred = train_set.drop([\"id\", \"date\", \"lat\", \"long\"], axis=1)\n",
    "\n",
    "# check for multicolinearity with seaborn heatmap\n",
    "# compute the correlation matrix\n",
    "corr = round(train_set_pred.corr(numeric_only=True), 3)\n",
    "\n",
    "# set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "# generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax = sns.heatmap(corr, cmap=cmap, vmax=1, vmin=-1, center=0, square=True, linewidths=1, cbar_kws={\"shrink\": .75}, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correlation matrix is simmetrical we can get rid of the upper triangle using a triangular boolean mask: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Let's visualise the mask with matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.matshow(mask, cmap=\"gray\")\n",
    "\n",
    "for (i, j), z in np.ndenumerate(mask):\n",
    "    ax.text(j, i, '{:0.0f}'.format(z), ha='center', va='center', c=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0, square=True, linewidths=1, cbar_kws={\"shrink\": .75}, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "**Question:** what conclusions can we draw from this correlation matrix? Is there any redundant information in the dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preparing numerical data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['sqft_living','sqft_lot','sqft_above','sqft_basement','yr_built','sqft_living15','sqft_lot15']\n",
    "\n",
    "for feat in numerical_features:\n",
    "    sns.jointplot(\n",
    "        x=feat,\n",
    "        y=\"price\",\n",
    "        data=train_set,\n",
    "        kind='reg',\n",
    "        label=feat,\n",
    "        joint_kws={'line_kws':{'color':'orange'}}\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already seen in the multicolinearity test `sqft_living`, `sqft_living15`, and `sqft_above` predictors all seem to have prominent linear correlation with price, Of the three, we will use `sqft_living` as it is the one that mostly correlates with price. \n",
    "\n",
    "We can notice that there are a bunch of zeros in `sqft_basement`. That indicates that those homes do not have basements.To tackle that, we will create a binary feature that indicates whethere a house has a basement or not.\n",
    "\n",
    "Finally, `yr_built` does not seem to show any clear relationship with price. We could combine the information of `yr_built` with `yr_renovated` to see get a more useful information. We will create a `renovated` binary flag. If a house is older than 25 years (relative to the most recent data in the dataset) and has not been renovated we will set `renovated` to 0, otherwise to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Categorical and Ordinal Features\n",
    "\n",
    "Let's examine the categorical and ordinal features more closely. Boxplots and violin plots are the most suited type of graphs for plotting a categorical variable against a numerical one (i.e. our target variable `price`)\n",
    "\n",
    "First we need to convert these columns to the category type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['bedrooms','bathrooms','floors','waterfront','view','condition','grade','zipcode']\n",
    "train_set[categorical_features] = train_set[categorical_features].astype('category')\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then start using boxplots or violinplots to further investigate targeted correlations, such as 'grade' vs 'price' or 'floors' vs 'price'.\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "<b>Exercise 3:</b> write a function that takes a categorical or ordinal feature as a first argument, the size of a figure as a second argument and plots, using seaborn, a set of boxplots of the price distribution for each category in the input categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_boxplot(\n",
    "    data_set: pd.DataFrame,\n",
    "    feature: str, \n",
    "    figsize: tuple[int, int] = (14, 6), \n",
    "    xlabels_rotation: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    data_set: the dataset with the feature and price columns\n",
    "    feature: the name of the feature to plot against \"price\"\n",
    "    figsize: the (width, height) size of the figure\n",
    "    xlabels_rotation: the rotation of the X labels. Default is equivalent to no rotation\n",
    "    \"\"\"\n",
    "    # create a dataframe containing only feature and \"price\"\n",
    "    data = ...\n",
    "    # specify the size of the figure\n",
    "    ...\n",
    "    # create the feature vs price boxplot using seaborn. Check the seaborn boxplot documentation\n",
    "    chart = ...\n",
    "    # if an x-label rotation is provided, rotate the x label of the chart\n",
    "    if xlabels_rotation is not None:\n",
    "        chart.set_xticklabels(chart.get_xticklabels(), rotation=xlabels_rotation, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try your function to plot 'grade' vs 'price'.\n",
    "## If you have implemented it correctly it will plot out the boxplots\n",
    "print_boxplot(train_set, 'grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try your function to plot 'floors' vs 'price'.\n",
    "## If you have implemented it correctly it will plot out the boxplots\n",
    "print_boxplot(train_set, 'floors', figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try your function to plot 'bathrooms' vs 'price'.\n",
    "## If you have implemented it correctly it will plot out the boxplots\n",
    "print_boxplot(train_set, 'bathrooms', figsize=(20, 12))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "**Question:** Do you notice anything suspicious with bathrooms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_boxplot(train_set, 'bedrooms', figsize=(20, 12))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "**Question:** Do you notice anything suspicious with bedrooms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_boxplot(train_set, \"view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_boxplot(train_set, \"waterfront\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_boxplot(train_set, \"zipcode\", figsize=(24, 8), xlabels_rotation= 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Categorical variables: statistical test to evaluate significance (optional)\n",
    "\n",
    "#### ANOVA test for the \"view\" feature\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical test that analyses the difference among means. ANOVA checks if the means of two or more groups are significantly different from each other. In our case we want to see if the average prices are significantly different among the 5 view categories.\n",
    "\n",
    "We can compute ANOVA using the `statsmodels` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mod = ols(\"price ~ view\", train_set).fit()\n",
    "table = sm.stats.anova_lm(lin_mod, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p-value for view is 0.000 < 0.05, the difference of average house prices among the view categories is significant.\n",
    "\n",
    "#### Post-hoc test\n",
    "\n",
    "We can run a post-hoc test to make pairwise comparisons and see which pairs of view categories have significant mean differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_t = lin_mod.t_test_pairwise(\"view\")\n",
    "pair_t.result_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the differences are significant except between view 1 and view 2. This could already be discerned from the boxplot graph. We could then rework the view categories merging together views 1 and 2 and reducing the 5 categories to 4.\n",
    "\n",
    "Another option would be convert this feature to a binary one (\"view\" vs \"no view\"). For our model training we will keep all the view levels and treat it as an ordinal variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA and post-hoc tests on ZIPCODE\n",
    "\n",
    "We could do a symilar analysis on the `zipcode` field to reduce the number of categories there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = train_set[\"zipcode\"].unique()\n",
    "zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 70 zipcodes. That is a bit too many categories given the number of samples we have. A plurality of these zipcodes likely have very few samples so we may encur into overfitting our models. We could find a way to cluster/collapse these zipcodes together, based on whether\n",
    "their average house price is significantly different or not.\n",
    "To do this we can first do an ANOVA test on `zipcode` and their peform pairwise post-hoc t-test and then collapse together those zipcodes whose t-test indicates that the means are not significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mod = ols(\"price ~ zipcode\", train_set).fit()\n",
    "table = sm.stats.anova_lm(lin_mod, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p-value for view is 0.000 < 0.05, the difference of average house prices among the view categories is significant.\n",
    "\n",
    "#### Post-hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_t = lin_mod.t_test_pairwise(\"zipcode\")\n",
    "pair_t.result_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract the zipcode pairs whose post-hoc t-test fails to reject the null hypothesis (i.e. the average prices are not significantly different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttests_frame = pair_t.result_frame[pair_t.result_frame[\"reject-hs\"].isin([False])].reset_index(names=\"zipcode-pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttests_frame[\"zipcode-pairs\"] = ttests_frame[\"zipcode-pairs\"].str.split(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttests_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll group together all the zipcodes for which the mean house price is not significantly different. In doing so, we will create a new category named `zipcode_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zipcode_groups(data_set: pd.DataFrame) -> list[set]:\n",
    "    \"\"\"\n",
    "    Groups together zipcodes with similar house prices\n",
    "    :param data_set: it can be the training or test set\n",
    "    :returns: he generated zipcode groups. Each zipcode group is a set\n",
    "    \"\"\"\n",
    "    # firsr we perform a post-hoc t-test with correction for each zipcode pair\n",
    "    pair_t = ols(\"price ~ zipcode\", train_set).fit().t_test_pairwise(\"zipcode\")\n",
    "    # we retain all the zipcode pairs for which the post-hoc test fails to reject the null hypothesis\n",
    "    # these are all the zipcode pairs whose average house price is not significantly different with a 95% CI\n",
    "    t_tests_frame = pair_t.result_frame[pair_t.result_frame[\"reject-hs\"].isin([False])].reset_index(names=\"zipcode-pairs\")\n",
    "    # we extract the zipcode pairs as a list\n",
    "    zipcode_pairs = t_tests_frame[\"zipcode-pairs\"].str.split(\"-\").tolist()\n",
    "    # we group together zipcodes with \"similar\" average house prices\n",
    "    zipcode_groups = []\n",
    "    for zipcode in train_set[\"zipcode\"].unique():\n",
    "        if any(zipcode in group for group in zipcode_groups):\n",
    "            continue\n",
    "        new_group = { zipcode }\n",
    "        for pair in zipcode_pairs:\n",
    "            if zipcode in pair:\n",
    "                new_group.update(pair)\n",
    "        zipcode_groups.append(new_group)\n",
    "    return zipcode_groups "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "**Exercise 4:** Let's test the function `make_zipcode_groups()` on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced our 70 zipcodes to just 9 zipcode groups. This should not impact too much our predictive power wrt `price` while reducing the risk of overfitting.\n",
    "\n",
    "We can now assign each sample in the training and test set a `zipcode_group` feature based on its zipcode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_zipcode_group(zipcode: str, zipcode_groups: list[set], group_prefix=\"zg\") -> str:\n",
    "    \"\"\"\n",
    "    given a zipcode and a list of groups it assign a zipcode to a group\n",
    "    The groups will be called using the group_prefix as a prefix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res = next(i for i, group in enumerate(zipcode_groups) if zipcode in group)\n",
    "        return f\"{group_prefix}_{res}\"\n",
    "    except StopIteration:\n",
    "        # we need to take into account that some zipcode may be missing in the training set and present in the test set\n",
    "        return f\"{group_prefix}_other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"zipcode_group\"] = train_set[\"zipcode\"].apply(assign_to_zipcode_group, zipcode_groups=zipcode_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"zipcode_group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"zipcode_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: as an expected consequence of our clustering, some zipcode groups are now over-represented in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"zipcode_group\"] = test_set[\"zipcode\"].apply(assign_to_zipcode_group, zipcode_groups=zipcode_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"zipcode_group\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out all the zipcodes were present in the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusions of the EDA:\n",
    "\n",
    "At the end of our EDA we have reached a few conclusions:\n",
    "\n",
    "* We have identified quantitative, ordinal and categorical variables.\n",
    "* We have identified a cutoff at latitude  ~47.5 between more expensive houses and cheaper houses.We will create a binary engineered feature to capture this. We could also create a cutoff at -126.1 long to separate the urban west from the rural east of the county. We will then remove `lat` and `long`.\n",
    "* We have decided to discard `sqft_living15` and `sqft_living_above` in favour of `sqft_living`\n",
    "* We have decided to add a binary engineered feature that indicates whether a house has a basement or not. We will then remove the continuous variable `sqft_basement`\n",
    "* We will create a renovated binary flag. If a house is older than 25 years (relative to the most recent data in the dataset) and has not been renovated we will set renovated to 0, otherwise to 1. We will then remove the continuous variable `yr_built` and `yr__renovated`\n",
    "* We have decided to collapse the 70 zipcodes into 9 zipcode groups based on average house prices in the zipcodes \n",
    "* Some houses report 0 bathrooms. We need to replace those values with more meaningful estimates.\n",
    "* One house has 33 bedrooms. We will replace that value with 3, as it looks like a reporting mistake."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
